{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching of curves, optimal transport v kernel-varifold data attachment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preliminary imports to get the right path to lddmm_python...\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "PACKAGE_PARENT = '..'\n",
    "SCRIPT_DIR = os.path.dirname(module_path)\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lddmm_python  # My library folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pylab import pause, inf\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "# Import of the relevant manifold\n",
    "from lddmm_python.modules.manifolds.theano_curves import TheanoCurves\n",
    "from lddmm_python.modules.manifolds.curves import Curve\n",
    "from lddmm_python.modules.data_attachment.sinkhorn  import SinkhornOptions\n",
    "from lddmm_python.modules.data_attachment.varifolds import VarifoldOptions\n",
    "from lddmm_python.modules.io.level_lines import level_curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To illustrate the efficiency of the OT data attachment term,\n",
    "# we now solve a simple matching problem between two curves in the plane.\n",
    "\n",
    "npoints  = 200\n",
    "\n",
    "q0 = level_curves('data/source.png', npoints)\n",
    "Xt = level_curves('data/target.png', npoints)\n",
    "    \n",
    "all_pts = np.vstack((q0.to_array(), Xt.to_array()))\n",
    "mini = np.amin(all_pts, axis=0)\n",
    "maxi = np.amax(all_pts, axis=0)\n",
    "midpoint = .5 * (mini + maxi)\n",
    "axis_len = maxi - mini\n",
    "\n",
    "m0 = midpoint ; s0 = np.amax(axis_len)\n",
    "\n",
    "q0.translate_rescale(m0, s0)\n",
    "Xt.translate_rescale(m0, s0)\n",
    "print('Data have been rescaled to fit in the unit square.')\n",
    "\n",
    "# Convert the source Q0 and the target Xt from Pythonic objects to simple numpy arrays\n",
    "Q0 = q0.to_array()\n",
    "nq = len(Q0) ; d  = Q0.shape[1]\n",
    "\n",
    "Xt_emb = Xt.to_varifold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_matching(foldername, \n",
    "                     details_scale, max_interaction_scale, \n",
    "                     attachment_type, \n",
    "                     orientation_weight, orientation_order,\n",
    "                     maxit_sinkhorn = 10000, maxit_descent = 1000) :\n",
    "    \n",
    "    if attachment_type == 'varifold-kernel' :\n",
    "        use_transport = False\n",
    "    elif attachment_type == 'varifold-sinkhorn' :\n",
    "        use_transport = True\n",
    "    # ========================================================================================   \n",
    "    if not use_transport :\n",
    "        data_attachment = (attachment_type, ('gaussian', details_scale))\n",
    "    else :\n",
    "        # In the paper, we use a simple \"transport-only/Wasserstein\" cost, with autodiff,\n",
    "        # which is the \"bug-proofed\" version.\n",
    "        data_attachment = (attachment_type, \n",
    "                          (VarifoldOptions(\n",
    "                                orientation_weight = orientation_weight,\n",
    "                                orientation_order  = orientation_order ),\n",
    "                           SinkhornOptions(\n",
    "                                epsilon         = details_scale**2,\n",
    "                                niter           = maxit_sinkhorn,  # Won't be reached in practice\n",
    "                                rho             = max_interaction_scale**2,\n",
    "                                tau             = -.8,    # Good enough acceleration\n",
    "                                dual_cost       = False,  # (Dual v) Primal\n",
    "                                discard_entropy = True,   # Remove  (v Keep) the -eps*H(g) in the primal\n",
    "                                discard_KL      = True,   # Discard (v Compute) the rho * KL(...) term ?\n",
    "                                grad_hack       = False,  # (Maths v) AutoDiff\n",
    "                                display_error   = False   # True if you want to show the Sinkhorn number of steps, but it involves a slight hacl\n",
    "                            )  ) )\n",
    "        \n",
    "    M = TheanoCurves(q0,      # TheanoCurves models the orbit of the curve q0 \n",
    "                 kernel = ('gaussian', [(1., .025), (.75, .15)]), # Good enough kernel : high frequencies + large carriage\n",
    "                 weights               = (0.001, 1), # Weights : 1. for the attachment, 1e-3 for the geodesic squared length\n",
    "                 data_attachment       = data_attachment,\n",
    "                 plot_interactive      = False,\n",
    "                 plot_file             = True,\n",
    "                 foldername            = 'results/vtk_files/' + foldername\n",
    "                )\n",
    "    \n",
    "    # =========================================================================================\n",
    "    # Local density estimation - useful for the LBFGS preconditionning :\n",
    "    # the shooting is parametrized by a normalized moment r0\n",
    "\n",
    "    vertex = T.matrix()\n",
    "    M_kernel = theano.function([vertex], M._Kq(vertex), allow_input_downcast=True)\n",
    "    K_Q0 = M_kernel(Q0)\n",
    "    dens = np.sum(K_Q0, 1)\n",
    "\n",
    "    def p0_from_r0(r0) :\n",
    "        p0 = r0.reshape((nq,d))\n",
    "        p0 =  (p0.T * (1./ dens)).T\n",
    "        return p0\n",
    "    def dr0_from_dp0(dp0) :\n",
    "        \"Adjoint of a pointwise multiplication and transposes : self.\"\n",
    "        dr0 = (dp0.T * (1./ dens)).T\n",
    "        dr0 = dr0.ravel()\n",
    "        return dr0\n",
    "    # ======================================================================================================\n",
    "    # L-BFGS minimization \n",
    "    nits  = maxit_descent # max number of iterations\n",
    "    P0 = np.zeros((nq,d)) # Null initialization for the shooting momentum\n",
    "    \n",
    "    # N.B. : in actual fact, we plot every single model/plan along the line search,\n",
    "    #        not only those that actually correspond to a BFGS descent.\n",
    "    #        This is more accurate to estimate the cost of the algorithm.\n",
    "    def matching_problem(r0) :\n",
    "        p0 = p0_from_r0(r0)\n",
    "\n",
    "        matching_problem.it += 1\n",
    "        [c, dq_c, dp_c, q1, cost_info] = M.shooting_cost(Q0, p0, target = Xt_emb)\n",
    "        print('Cost value : ', c)\n",
    "        plan = cost_info\n",
    "        M.quiver(Q0, p0 ,                name='Descent/Momentums/Momentum_'+str(matching_problem.it))\n",
    "        M.marker(q1,                     name='Descent/Models/Model_'+str(matching_problem.it))\n",
    "        if use_transport :\n",
    "            M.show_transport(q1, Xt, plan,   name='Descent/Plans/Plan_'+str(matching_problem.it))\n",
    "        # The fortran routines used by scipy.optimize expect float64 vectors\n",
    "        # instead of the gpu-friendly float32 matrices :\n",
    "        dr0 = dr0_from_dp0(dp_c)\n",
    "        return (c, dr0.astype('float64'))\n",
    "\n",
    "    matching_problem.it = 0\n",
    "\n",
    "    time1 = time.time()\n",
    "    res = minimize( matching_problem,     # function to minimize\n",
    "                    P0.ravel(),           # starting estimate\n",
    "                    method = 'L-BFGS-B',  # an order 2 method\n",
    "                    jac = True,           # matching_problems also returns the gradient\n",
    "                    options = dict(\n",
    "                        disp    = True,\n",
    "                        maxiter = nits,   # Won't be reached in practice\n",
    "                        ftol    = .0000001, # Don't bother fitting the shapes to float precision, even for the paper...\n",
    "                        maxcor  = 10      # Number of previous gradients used to approximate the Hessian\n",
    "                    ))\n",
    "    time2 = time.time()\n",
    "\n",
    "    P0 = p0_from_r0(res.x)\n",
    "    print('Convergence success  : ', res.success, ', status = ', res.status)\n",
    "    print('Optimization message : ', res.message.decode('UTF-8'))\n",
    "    print('Final cost   after ', res.nit, ' iterations : ', res.fun)    \n",
    "    print('Elapsed time after ', res.nit, ' iterations : ', '{0:.2f}'.format(time2 - time1), 's')\n",
    "    \n",
    "    # =================================================================================================\n",
    "    # Visualize the end point\n",
    "    [Qt, Pt] = M.hamiltonian_trajectory(Q0, P0)\n",
    "\n",
    "    M.current_axis = []\n",
    "    M.marker(Q0,     name='Template')\n",
    "    M.plot_traj(Qt,  name='Shoot/Shoot')\n",
    "    M.plot_momentums(Qt, Pt, name='Momentums/Momentum')\n",
    "    M.marker(Qt[-1], name='Model')\n",
    "\n",
    "    M.marker_target(Xt,name='Target')\n",
    "    \n",
    "    Gt = M.grid_trajectory(Q0, P0, [(-.5,.5), (-.5,.5)], nlines = 21)\n",
    "    M.file_plot_grids(Gt, 'Grid/grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## Time to compute all that !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True :\n",
    "    compute_matching('kernel_big/'  ,  .2,  .2, 'varifold-kernel',   1., 4)\n",
    "    compute_matching('kernel_small/', .05, .05, 'varifold-kernel',   1., 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True :\n",
    "    compute_matching('sinkhorn_eps-m_rho-s/', .03,  .1, 'varifold-sinkhorn', 1., 4)\n",
    "    compute_matching('sinkhorn_eps-m_rho-m/', .03, .15, 'varifold-sinkhorn', 1., 4)\n",
    "    compute_matching('sinkhorn_eps-m_rho-l/', .03,  .5, 'varifold-sinkhorn', 1., 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True :\n",
    "    compute_matching('sinkhorn_eps-l_rho-l/', .1,   .5, 'varifold-sinkhorn', 1., 4)\n",
    "    #compute_matching('sinkhorn_eps-m_rho-l/', .03,  .5, 'varifold-sinkhorn', 1., 4)\n",
    "    compute_matching('sinkhorn_eps-s_rho-l/', .015, .5, 'varifold-sinkhorn', 1., 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False : # just to see how the plan evolves with the number of sinkhorn iterations\n",
    "    compute_matching('sinkhorn_it5/', .05, .5, 'varifold-sinkhorn', 1., 4, maxit_sinkhorn = 5, maxit_descent = 2)\n",
    "    compute_matching('sinkhorn_it10/', .05, .5, 'varifold-sinkhorn', 1., 4, maxit_sinkhorn = 10, maxit_descent = 2)\n",
    "    compute_matching('sinkhorn_it25/', .05, .5, 'varifold-sinkhorn', 1., 4, maxit_sinkhorn = 25, maxit_descent = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Optirun",
   "language": "python",
   "name": "optirun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
