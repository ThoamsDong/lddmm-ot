{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching of curves, optimal transport v kernel-varifold data attachment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preliminary imports to get the right path to lddmm_python...\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "PACKAGE_PARENT = '..'\n",
    "SCRIPT_DIR = os.path.dirname(module_path)\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lddmm_python  # My library folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pylab import pause, inf\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "# Import of the relevant manifold\n",
    "from lddmm_python.modules.manifolds.theano_curves import TheanoCurves\n",
    "from lddmm_python.modules.manifolds.curves import Curve\n",
    "from lddmm_python.modules.data_attachment.sinkhorn  import SinkhornOptions\n",
    "from lddmm_python.modules.data_attachment.varifolds import VarifoldOptions\n",
    "from lddmm_python.modules.io.level_lines import level_curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data have been rescaled to fit in the unit square.\n"
     ]
    }
   ],
   "source": [
    "# To illustrate the efficiency of the OT data attachment term,\n",
    "# we now solve a simple matching problem between two curves in the plane.\n",
    "\n",
    "npoints  = 200\n",
    "\n",
    "q0 = level_curves('data/source.png', npoints)\n",
    "Xt = level_curves('data/target.png', npoints)\n",
    "    \n",
    "all_pts = np.vstack((q0.to_array(), Xt.to_array()))\n",
    "mini = np.amin(all_pts, axis=0)\n",
    "maxi = np.amax(all_pts, axis=0)\n",
    "midpoint = .5 * (mini + maxi)\n",
    "axis_len = maxi - mini\n",
    "\n",
    "m0 = midpoint ; s0 = np.amax(axis_len)\n",
    "\n",
    "q0.translate_rescale(m0, s0)\n",
    "Xt.translate_rescale(m0, s0)\n",
    "print('Data have been rescaled to fit in the unit square.')\n",
    "\n",
    "# Convert the source Q0 and the target Xt from Pythonic objects to simple numpy arrays\n",
    "Q0 = q0.to_array()\n",
    "nq = len(Q0) ; d  = Q0.shape[1]\n",
    "\n",
    "Xt_emb = Xt.to_varifold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_matching(foldername, \n",
    "                     details_scale, max_interaction_scale, \n",
    "                     attachment_type, \n",
    "                     orientation_weight, orientation_order,\n",
    "                     maxit_sinkhorn = 10000, maxit_descent = 1000) :\n",
    "    \n",
    "    if attachment_type == 'varifold-kernel' :\n",
    "        use_transport = False\n",
    "    elif attachment_type == 'varifold-sinkhorn' :\n",
    "        use_transport = True\n",
    "    # ========================================================================================   \n",
    "    if not use_transport :\n",
    "        data_attachment = (attachment_type, ('gaussian', details_scale))\n",
    "    else :\n",
    "        # In the paper, we use a simple \"transport-only/Wasserstein\" cost, with autodiff,\n",
    "        # which is the \"bug-proofed\" version.\n",
    "        data_attachment = (attachment_type, \n",
    "                          (VarifoldOptions(\n",
    "                                orientation_weight = orientation_weight,\n",
    "                                orientation_order  = orientation_order ),\n",
    "                           SinkhornOptions(\n",
    "                                epsilon         = details_scale**2,\n",
    "                                niter           = maxit_sinkhorn,  # Won't be reached in practice\n",
    "                                rho             = max_interaction_scale**2,\n",
    "                                tau             = -.8,    # Good enough acceleration\n",
    "                                dual_cost       = False,  # (Dual v) Primal\n",
    "                                discard_entropy = True,   # Remove  (v Keep) the -eps*H(g) in the primal\n",
    "                                discard_KL      = True,   # Discard (v Compute) the rho * KL(...) term ?\n",
    "                                grad_hack       = False,  # (Maths v) AutoDiff\n",
    "                                display_error   = False   # True if you want to show the Sinkhorn number of steps, but it involves a slight hacl\n",
    "                            )  ) )\n",
    "        \n",
    "    M = TheanoCurves(q0,      # TheanoCurves models the orbit of the curve q0 \n",
    "                 kernel = ('gaussian', [(1., .025), (.75, .15)]), # Good enough kernel : high frequencies + large carriage\n",
    "                 weights               = (0.001, 1), # Weights : 1. for the attachment, 1e-3 for the geodesic squared length\n",
    "                 data_attachment       = data_attachment,\n",
    "                 plot_interactive      = False,\n",
    "                 plot_file             = True,\n",
    "                 foldername            = 'results/vtk_files/' + foldername\n",
    "                )\n",
    "    def assert_folder(dname) :\n",
    "        if not os.path.exists(dname):\n",
    "            os.makedirs(dname)\n",
    "    assert_folder(M.foldername + '/Descent/Grids/')\n",
    "    # =========================================================================================\n",
    "    # Local density estimation - useful for the LBFGS preconditionning :\n",
    "    # the shooting is parametrized by a normalized moment r0\n",
    "\n",
    "    vertex = T.matrix()\n",
    "    M_kernel = theano.function([vertex], M._Kq(vertex), allow_input_downcast=True)\n",
    "    K_Q0 = M_kernel(Q0)\n",
    "    dens = np.sum(K_Q0, 1)\n",
    "\n",
    "    def p0_from_r0(r0) :\n",
    "        p0 = r0.reshape((nq,d))\n",
    "        p0 =  (p0.T * (1./ dens)).T\n",
    "        return p0\n",
    "    def dr0_from_dp0(dp0) :\n",
    "        \"Adjoint of a pointwise multiplication and transposes : self.\"\n",
    "        dr0 = (dp0.T * (1./ dens)).T\n",
    "        dr0 = dr0.ravel()\n",
    "        return dr0\n",
    "    # ======================================================================================================\n",
    "    # L-BFGS minimization \n",
    "    nits  = maxit_descent # max number of iterations\n",
    "    P0 = np.zeros((nq,d)) # Null initialization for the shooting momentum\n",
    "    \n",
    "    # N.B. : in actual fact, we plot every single model/plan along the line search,\n",
    "    #        not only those that actually correspond to a BFGS descent.\n",
    "    #        This is more accurate to estimate the cost of the algorithm.\n",
    "    def matching_problem(r0) :\n",
    "        p0 = p0_from_r0(r0)\n",
    "\n",
    "        matching_problem.it += 1\n",
    "        [c, dq_c, dp_c, q1, cost_info] = M.shooting_cost(Q0, p0, target = Xt_emb)\n",
    "        print('Cost value : ', c)\n",
    "        plan = cost_info\n",
    "        M.quiver(Q0, p0 ,                name='Descent/Momentums/Momentum_'+str(matching_problem.it))\n",
    "        M.marker(q1,                     name='Descent/Models/Model_'+str(matching_problem.it))\n",
    "        if use_transport :\n",
    "            M.show_transport(q1, Xt, plan,   name='Descent/Plans/Plan_'+str(matching_problem.it))\n",
    "            np.savetxt(M.foldername+'Descent/Plans/plan_'+str(matching_problem.it)+'.csv', plan)\n",
    "        gt = M.grid_trajectory(Q0, p0, [(-.5,.5), (-.5,.5)])\n",
    "        g1 = gt[-1]\n",
    "        g1.to_file(M.foldername + 'Descent/Grids/Grid_'+str(matching_problem.it)+'.vtk')\n",
    "        # The fortran routines used by scipy.optimize expect float64 vectors\n",
    "        # instead of the gpu-friendly float32 matrices :\n",
    "        dr0 = dr0_from_dp0(dp_c)\n",
    "        return (c, dr0.astype('float64'))\n",
    "\n",
    "    matching_problem.it = 0\n",
    "\n",
    "    time1 = time.time()\n",
    "    res = minimize( matching_problem,     # function to minimize\n",
    "                    P0.ravel(),           # starting estimate\n",
    "                    method = 'L-BFGS-B',  # an order 2 method\n",
    "                    jac = True,           # matching_problems also returns the gradient\n",
    "                    options = dict(\n",
    "                        disp    = True,\n",
    "                        maxiter = nits,   # Won't be reached in practice\n",
    "                        ftol    = .0000001, # Don't bother fitting the shapes to float precision, even for the paper...\n",
    "                        maxcor  = 10      # Number of previous gradients used to approximate the Hessian\n",
    "                    ))\n",
    "    time2 = time.time()\n",
    "\n",
    "    P0 = p0_from_r0(res.x)\n",
    "    print('Convergence success  : ', res.success, ', status = ', res.status)\n",
    "    print('Optimization message : ', res.message.decode('UTF-8'))\n",
    "    print('Final cost   after ', res.nit, ' iterations : ', res.fun)    \n",
    "    print('Elapsed time after ', res.nit, ' iterations : ', '{0:.2f}'.format(time2 - time1), 's')\n",
    "    \n",
    "    # =================================================================================================\n",
    "    # Visualize the end point\n",
    "    [Qt, Pt] = M.hamiltonian_trajectory(Q0, P0)\n",
    "\n",
    "    M.current_axis = []\n",
    "    M.marker(Q0,     name='Template')\n",
    "    M.plot_traj(Qt,  name='Shoot/Shoot')\n",
    "    M.plot_momentums(Qt, Pt, name='Momentums/Momentum')\n",
    "    M.marker(Qt[-1], name='Model')\n",
    "\n",
    "    M.marker_target(Xt,name='Target')\n",
    "    \n",
    "    Gt = M.grid_trajectory(Q0, P0, [(-.5,.5), (-.5,.5)], nlines = 21)\n",
    "    M.file_plot_grids(Gt, 'Grid/grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## Time to compute all that !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    compute_matching('kernel_big/'  ,  .2,  .2, 'varifold-kernel',   1., 4)\n",
    "    compute_matching('kernel_small/', .05, .05, 'varifold-kernel',   1., 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    compute_matching('sinkhorn_eps-m_rho-s/', .03,  .1, 'varifold-sinkhorn', 1., 4)\n",
    "    compute_matching('sinkhorn_eps-m_rho-m/', .03, .15, 'varifold-sinkhorn', 1., 4)\n",
    "    compute_matching('sinkhorn_eps-m_rho-l/', .03,  .5, 'varifold-sinkhorn', 1., 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the shooting_cost routine...\n",
      "Compiled in :  396.23 s\n",
      "Compiling the hamiltonian_trajectory visualization routine...\n",
      "Compiled in :  10.30 s\n",
      "Compiling the hamiltonian_trajectory_carrying visualization routine...\n",
      "Compiled in :  13.60 s\n",
      "Cost value :  0.10193442553281784\n",
      "Cost value :  0.0679963156580925\n",
      "Cost value :  0.08893703669309616\n",
      "Cost value :  0.018759487196803093\n",
      "Cost value :  0.01664315164089203\n",
      "Cost value :  0.0044412617571651936\n",
      "Cost value :  0.003231660695746541\n",
      "Cost value :  0.002756633562967181\n",
      "Cost value :  0.0023452823515981436\n",
      "Cost value :  0.0019332080846652389\n",
      "Cost value :  0.0017540091648697853\n",
      "Cost value :  0.001669414690695703\n",
      "Cost value :  0.001583990640938282\n",
      "Cost value :  0.0014706203946843743\n",
      "Cost value :  0.0013726367615163326\n",
      "Cost value :  0.0013154925545677543\n",
      "Cost value :  0.0012785032158717513\n",
      "Cost value :  0.0012312971521168947\n",
      "Cost value :  0.0011542406864464283\n",
      "Cost value :  0.001043603173457086\n",
      "Cost value :  0.0010196518851444125\n",
      "Cost value :  0.0009563721832819283\n",
      "Cost value :  0.0009037259733304381\n",
      "Cost value :  0.0008747359970584512\n",
      "Cost value :  0.0008325856761075556\n",
      "Cost value :  0.0007968303980305791\n",
      "Cost value :  0.0007777533610351384\n",
      "Cost value :  0.0007632957422174513\n",
      "Cost value :  0.0007552848546765745\n",
      "Cost value :  0.0007385563221760094\n",
      "Cost value :  0.0007257070974446833\n",
      "Cost value :  0.0007124477415345609\n",
      "Cost value :  0.000705537386238575\n",
      "Cost value :  0.0006977126467972994\n",
      "Cost value :  0.0006887641502544284\n",
      "Cost value :  0.0006738711963407695\n",
      "Cost value :  0.0006721309036947787\n",
      "Cost value :  0.0006604965892620385\n",
      "Cost value :  0.0006557301385328174\n",
      "Cost value :  0.0006506145000457764\n",
      "Cost value :  0.0006473145913332701\n",
      "Cost value :  0.0006431705551221967\n",
      "Cost value :  0.0006388449110090733\n",
      "Cost value :  0.0006350617040880024\n",
      "Cost value :  0.0006348054157570004\n",
      "Cost value :  0.0006303826230578125\n",
      "Cost value :  0.0006292202160693705\n",
      "Cost value :  0.0006277263164520264\n",
      "Cost value :  0.0006244712276384234\n",
      "Cost value :  0.0006224714452400804\n",
      "Cost value :  0.0006202258518896997\n",
      "Cost value :  0.0006188212428241968\n",
      "Cost value :  0.0006173348519951105\n",
      "Cost value :  0.0006165812956169248\n",
      "Cost value :  0.0006144513608887792\n",
      "Cost value :  0.0006134495488367975\n",
      "Cost value :  0.0006119107129052281\n",
      "Cost value :  0.0006094424170441926\n",
      "Cost value :  0.0006075059063732624\n",
      "Cost value :  0.0006053679389879107\n",
      "Cost value :  0.0006042315508238971\n",
      "Cost value :  0.0006029042415320873\n",
      "Cost value :  0.0006012271624058485\n",
      "Cost value :  0.0005997170228511095\n",
      "Cost value :  0.0005980681744404137\n",
      "Cost value :  0.0005977530381642282\n",
      "Cost value :  0.0005965532618574798\n",
      "Cost value :  0.0005959728150628507\n",
      "Convergence success  :  True , status =  0\n",
      "Optimization message :  CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Final cost   after  66  iterations :  0.0005959728150628507\n",
      "Elapsed time after  66  iterations :  635.31 s\n"
     ]
    }
   ],
   "source": [
    "if True :\n",
    "    #compute_matching('sinkhorn_eps-l_rho-l/', .1,   .5, 'varifold-sinkhorn', 1., 4)\n",
    "    #compute_matching('sinkhorn_eps-m_rho-l/', .03,  .5, 'varifold-sinkhorn', 1., 4)\n",
    "    compute_matching('sinkhorn_eps-s_rho-l/', .015, .5, 'varifold-sinkhorn', 1., 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False : # just to see how the plan evolves with the number of sinkhorn iterations\n",
    "    compute_matching('sinkhorn_it5/', .05, .5, 'varifold-sinkhorn', 1., 4, maxit_sinkhorn = 5, maxit_descent = 2)\n",
    "    compute_matching('sinkhorn_it10/', .05, .5, 'varifold-sinkhorn', 1., 4, maxit_sinkhorn = 10, maxit_descent = 2)\n",
    "    compute_matching('sinkhorn_it25/', .05, .5, 'varifold-sinkhorn', 1., 4, maxit_sinkhorn = 25, maxit_descent = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Optirun",
   "language": "python",
   "name": "optirun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
